{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import dotenv \n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Load\n",
    "Specify a DocumentLoader to load in your unstructured data as Documents.\n",
    "\n",
    "A Document is a `dict` with text (page_content) and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = '../data/raw/Personalization_strategies_in_digital_mental_healt.pdf'\n",
    "\n",
    "loader = PyPDFLoader(file_path)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Split\n",
    "Split the Document into chunks for embedding and vector storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split documents\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 0)\n",
    "splits = text_splitter.split_documents(loader.load())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Store\n",
    "To be able to look up our document splits, we first need to store them where we can later look them up.\n",
    "\n",
    "The most common way to do this is to embed the contents of each document split.\n",
    "\n",
    "We store the embedding and splits in a vectorstore.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed and store splits\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=splits,embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Retrieve\n",
    "Retrieve relevant splits for any question using similarity search.\n",
    "\n",
    "This is simply \"top K\" retrieval where we select documents based on embedding similarity to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['question', 'context'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question', 'context'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt \n",
    "# https://smith.langchain.com/hub/rlm/rag-prompt\n",
    "from langchain import hub\n",
    "\n",
    "rag_prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "rag_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG chain \n",
    "\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()} \n",
    "    | rag_prompt \n",
    "    | llm \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Silvan, full name Silvan Hornstein, is a correspondent for a research paper on personalization strategies in digital mental health interventions. He is also currently employed as a Data Scientist by Elona Health, a digital mental health start-up.')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"Who is Silvan?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The specific content of the paper is not clearly stated in the provided context. However, it appears to involve a review and analysis of certain interventions, possibly related to digital health or mental health, given the source file name. The authors also seem to have contacted other authors for clarification on certain points, suggesting a comprehensive research process.')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What is the paper about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The personalization strategies used include rule-based personalization for communication and guidance, and user choice-based personalization for content. Rule-based personalization might involve reminders for inactivity or non-completion, or increased guidance or clinician contact for symptom changes. User choice-based personalization allows optional content to be selected by the patient.')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"Which personalization strategies are used?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The context provided does not clearly state the problem that the paper is trying to address.')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What problem is the paper trying to address?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The problem with personalization strategies in digital mental health interventions is that there are major questions that remain open. These include understanding what personalization is, how prevalent it is in practice, and what benefits it truly has. There is also a need to define personalization in terms of intervention content, order, guidance, or communication.')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What problem is the problem with personalization strategies in digital mental health interventions?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_etudes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
